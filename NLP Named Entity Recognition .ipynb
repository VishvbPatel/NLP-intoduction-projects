{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Named Entity Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The named entity recognition is used to find named entities in the text like, organization, person, location, date, time, money, percent, facility and geo-political entitiy. Here, the nltk library is used to find out the named entities. In other words, the named entity recognition is ued to find the general understanding of what the text is about. The nltk library has also option to find the general named entity rather than finding it in different categories like, organization, person, location, etc. The general named entity can be gained by adding \"binary = True\" in the attributes of \"nltk.ne_chunk\" along with \"tagged\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk                                        #importing nltk library\n",
    "from nltk.corpus import state_union                #importing state_union for adding the speech\n",
    "from nltk.tokenize import PunktSentenceTokenizer   #importing the \"PunktSentenceTokenizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = state_union.raw(\"2005-GWBush.txt\")  #adding train text\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\") #adding sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)  #tokenizing train text with the help of \"PunktSentenceTokenizer\"\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)     #tokenizing the sample text with the help of trained train_text\n",
    "\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)    #seperating words with word_tokenize\n",
    "            tagged = nltk.pos_tag(words)     #seperating tags with pos_tag\n",
    "            namedEnt = nltk.ne_chunk(tagged) #Using \"nltk.ne_chunk\" to find the named entity.\"binary = True\" can be added here to get general named entity\n",
    "            \n",
    "            namedEnt.draw()                  #drawing the named entities\n",
    "            \n",
    "    except Exception as e:\n",
    "            print(str(e))\n",
    "            \n",
    "process_content()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
